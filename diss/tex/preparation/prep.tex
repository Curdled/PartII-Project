\documentclass[float=false, crop=false]{standalone}
\usepackage[subpreambles=true]{standalone}
\usepackage{import}

\usepackage{subfiles}
\usepackage[backend=biber,style=numeric,sorting=none]{biblatex}
\usepackage[pdfborder={0 0 0}]{hyperref}    % turns references into hyperlinks
\usepackage[margin=25mm]{geometry}  % adjusts page layout
\usepackage{graphicx}  % allows inclusion of PDF, PNG and JPG images
\usepackage[utf8]{inputenc}
\usepackage{textcomp}
\usepackage{import}
\usepackage[font=small,labelfont=bf]{caption}

\usepackage{amsmath}

\usepackage{csquotes}
\usepackage{color}

\usepackage{verbatim}

\newlength\gwidth
\newlength\gheight
\setlength{\gwidth}{\textwidth}
\setlength{\gwidth}{\textheight}

\newcommand{\namefig}{\textbf{Figure}~}

\renewcommand{\rmdefault}{bch} % change default font

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{tikz} 
\usetikzlibrary{arrows,decorations.pathmorphing,backgrounds,fit,positioning,shapes.symbols,chains}

\definecolor{pblue}{rgb}{0.13,0.13,1}
\definecolor{pgreen}{rgb}{0,0.5,0}
\definecolor{pred}{rgb}{0.9,0,0}
\definecolor{pgrey}{rgb}{0.46,0.45,0.48}

\usepackage{listings}
\lstnewenvironment{JavaLst}
{\lstset{language=Java,
  showspaces=false,
  showtabs=false,
  breaklines=true,
  showstringspaces=false,
  breakatwhitespace=true,
  commentstyle=\color{pgreen},
  keywordstyle=\color{pblue},
  stringstyle=\color{pred},
  basicstyle=\ttfamily,
  moredelim=[il][\textcolor{pgrey}]{$$},
  moredelim=[is][\textcolor{pgrey}]{\%\%}{\%\%}
}}{}

\lstnewenvironment{HaskellLst}
{\lstset{
  frame=none,
  xleftmargin=2pt,
  stepnumber=1,
  numbersep=5pt,
  numberstyle=\ttfamily\tiny\color[gray]{0.3},
  belowcaptionskip=\bigskipamount,
  commentstyle=\color{pgreen},
  keywordstyle=\color{pblue},
  stringstyle=\color{pred},
  basicstyle=\ttfamily,
  captionpos=b,
  escapeinside={*'}{'*},
  language=haskell,
  tabsize=2,
  emphstyle={\bf},
  commentstyle=\it,
  showspaces=false,
  columns=flexible,
  showstringspaces=false,
  morecomment=[l]\%,
}} {}

\lstnewenvironment{JVMLst}
{\lstset{
  frame=none,
  numbers=none,
  xleftmargin=2pt,
  language=JVMIS,
  emphstyle={\bf},
  stringstyle=\mdseries\rmfamily,
  commentstyle=\color{pgreen},
  stringstyle=\color{pred},
  keywordstyle=\color{black},
  basicstyle=\ttfamily,
  basicstyle=\small\sffamily
}} {}


\begin{document}

\section{Starting Point}


  I have taken the Compiler Construction course in Part IB and am currently taking the Part II course Types. I have spent the summer
  learning Haskell from various places including CIS 194 University of Pennsylvania \cite{cis194} and Real World Haskell \cite{realworldhaskell}.
  I plan to use Alex and Happy, which are lexer and parser generators
  respectively, to implement the first stage in the pipeline.
  I plan to use a library called \textit{codec-jvm} to generate JVM bytecode from an expression I will build up from the core language generated after
  syntactic desugaring. The \textit{codec-jvm} is a library that will allow me to build up a typed expression which will map directly
  to JVM bytecode. However, this library is just an assembler, I will still need to generate code to implement all of the
  programming language constructs in JVM bytecode myself.

\section{Requirements Analysis}

The layout of the project divided itself cleanly into five stages, the five stages are
\begin{enumerate}
  \item Lexing and Parsing.
  \item Desugaring.
  \item Type Inference.
  \item Optimisation.
  \item Code Generation.
\end{enumerate}

\begin{figure}
  \centering
  \subimport{stageDiagram/}{stageDiagram.tex}
  \caption{The five stages of the compiler}
\end{figure}

Each of these stages could be thought about in separation, therefore I will actively 
reduce code sharing between the pipeline stages and only have pipeline stages dependent 
on the previous stage, this will help reduce complexity between the stages and 
allow development of stages without relying on future 
stages. I will use a waterfall model, where I implement a stage
at a time in the order given above, while writing tests to help check
correctness of implementation.

I will in turn look at specific preparations made for each stage in the pipeline.

\textcolor{red}{Justify not including Type Classes.}

\section{Tools Used}

\begin{itemize}
  \item Git -- branch for new ideas.
  \item Vim + Haskell plugin -- No better IDE.
  \item IntelliJ Java IDE and decompiler -- Examine generated code and writing separate libraries.
  \item Cabal, manage complex project.
\end{itemize}  

  Haskell's default build system is called Cabal\cite{cabal}, I 
  decided Cabal 
  since there would be multiple included external libraries,
  many code files from my project and a benchmarking and test project
  that a build system would be very useful for managing all of this
  complexity. Cabal is very simple and provides support
  for many different project types:
  \begin{itemize}
    \item Library (This is how the compiler code is implemented).

    \item Executable (This is how the front end part of the compiler is 
      implemented).

    \item Test.

    \item Benchmark.
  \end{itemize}

  For writing unit tests I am using HUnit\cite{hunit},
  this provides a unit test framework and 
  also a quick-check framework. 
  I will use the unit test framework of the library, 
  to write tests for all stages of the compiler.

  Multiple parts of the compiler and outputted code will
  need to be benchmarked. I used a benchmarking library called
  Criterion\cite{criterion} for micro-benchmarks (running a function
  multiple times and finding the mean runtime with accuracy bounds).

\section{General}

I decided to write the compiler in Haskell, this choice was made for two reasons: 
\begin{itemize}
  \item Learning to program in Haskell, would help me better understand the Haskell language
    and therefore help in making more informed design decisions when implementing Haskell features.

  \item Functional programming languages lend themselves well to implementing a compiler. This is due to the fact that the compiler will just be operating
    on and modifying syntax trees, which functional languages excel at.

\end{itemize}

  The first preparation was to read fully and make notes on
  the Haskell report, this influenced design decisions from the start:
  noting the need for kind inference, I then decided to 
  place this process in the desugaring stage of the pipeline. 
  Then after reading the JVM 
  specification\cite{jvm-spec8} to figure out how each of the 
  Haskell constructs could be implemented on the JVM. I produced a
  document which my supervisor and I looked over and agreed
  on the fact this would be a simple and efficient implementation
  of the Haskell constructs. The document is included in 
  Appendix~\ref{appendix:bytecodetranslationdoc}. I will now discuss
  the decisions made for each stage of the pipeline before beginning
  the implementation.


\section{Lexing and Parsing}

I chose to use a lexing generator called Alex\cite{alex-lib} and a parsing generator called 
Happy\cite{happy-lib}.
These two libraries are very similar to Lex\cite{lex-lib} and Yacc\cite{yacc-lib}, but target
Haskell.
They both have manuals on their respective webpages which document creating a simple example and then
moving onto more complex examples.

I also looked at the Haskell 98 report \cite[2.,3.]{haskell98-spec}
to figure out what syntax JVHC will support and therefore, what 
should be supported by my lexer and parser implementations.
The implementation will not support all of the Haskell 98 
specification meaning that the 
language accepted by the lexer and parser could be simplified some what.

Haskell 98 is a whitespace sensitive language meaning that the parser must use a
context sensitive grammar to correctly parser a program:
\begin{HaskellLst}
f x = case x of 
  True  -> 1
  False -> 0
\end{HaskellLst}
Notice the double space before the \texttt{True} and \texttt{False}, this in conjunction with the
newline at the \texttt{1} is syntax for a cases statement. The Haskell 98 report
says how the parser should first insert \texttt{;},  \texttt{\{} and \texttt{\}} symbols at the 
relevant places:
\begin{HaskellLst}
f x = case of {
  True  -> 1;
  False -> 0
}
\end{HaskellLst}
This turns the whitespace sensitive language into a whitespace insensitive language. I chose to 
not implement a parser which would perform this translation since this would add extra complexity to the
implementation, I believe the parsing stage is less interesting than other stages in the pipeline.
This means my parser will accept programs defined using the whitespace insensitive 
syntax presented above.


\section{Desugaring}

The interesting part of the desugaring stage is 
checking that all custom data types which are declared at the top of a
file make sense in the context of Haskell. I will now explain this
problem in more detail.

Haskell has the notion of kinds, this is a form of type constructor. This will
formalize the notion of checking all custom data types declared.
The syntax of kinds is
\[ \mathtt{K} ::= \mathtt{*}\ |\ \mathtt{K}\  |\ \mathtt{K}_1 \rightarrow \mathtt{K}_2 \] 
Where \texttt{*} is called type and will match another
\texttt{*}, then \texttt{K} is a kind variable, and $\mathtt{K} \rightarrow \mathtt{K}$ is a type
to type constructor. Haskell also imposes another constraint that any type variable \texttt{K} will
be default to \texttt{*} (after kind inference) so as to give 
unique kind to each declaration without any kind variables.
The Haskell 98 report has a section \cite[4.6]{haskell98-spec} called Kind inference.
The example is drawn from that report:
\begin{HaskellLst}
data App f a = A (f a)
\end{HaskellLst}
This example will generate two constraints \texttt{a} has kind \texttt{K} and \texttt{f} 
has kind $\mathtt{K'} \rightarrow \mathtt{K}$. This \texttt{App} declaration will have kind  
kind $(\mathtt{*}\rightarrow\mathtt{*})\rightarrow\mathtt{*}\rightarrow
\mathtt{*}$.

The other part of the desugaring stage is to generate a syntax tree which can be used by the type checker
with appropriately simple syntactic constructs, reducing the number of cases that need
be considered in the type inference stage.

\section{Type Inference}

Type inference is the problem:
\begin{displayquote}
Given an expression $e$ find the type $\tau$ for the expression or return an error if not possible to
find a type for $e$.
\end{displayquote}
The solution to this section came mostly from a paper called `Typing Haskell in Haskell'\cite{thih-paper}. 
This provides a very clear outline on how to implement type inference. 
There are a few modifications that will be made to the approach.
Firstly I will remove any reference of type classes since they are not to be implemented in JVHC.
Secondly in the type checker a new expression data type called \texttt{CoreExpr} 
is generated which contains the type information discovered when running the type checker.

\texttt{CoreExpr} is a datatype with seven simple constructs which can express any expression in Haskell.
This data type was inspired by GHC\cite{typedcorelink}. This is a System F like typed lambda calculus with
built in support for constant values and data type deconstructors, in the form of \texttt{case} expressions.

\section{Inlining}

This section was inspired by a paper called ``Secrets of the 
Glasgow Haskell Compiler inliner''\cite{ghc-inliner}. This outlines the basic idea of functional 
inlining. The idea is given an expression:
\begin{HaskellLst}
let f x = x + 2 in 
  (f 2) + 4
\end{HaskellLst}
it could be reduced to
\begin{HaskellLst}
(2 + 2) + 4
\end{HaskellLst}
The transformation removes the overhead of allocating a new stack frame to call 
the function \texttt{f} at runtime.

The core calculus is System F but with recursive functions, 
this means that \textit{strong normalization}, 
need not hold, therefore care must be taken to make sure the inlining terminates.

\begin{displayquote} Strong normalization says that a well typed expression in System F will
reduce to a term with no $\beta$-redexes in a finite number of steps.
\end{displayquote}

\section{Code Generation}

I familiarized myself with the JVM8 specification \cite{jvm-spec8}, and finally wrote a 
document\ref{appendix:bytecodetranslationdoc} about how I would implement code generation, 
at a high level before starting to write any code.

To generate bytecode I will use the library Codec-JVM\cite{codec-jvm-link}. This library 
required me to specify the bytecode and the library would handle formatting the bytecode into
the \texttt{.class} file format accepted by the JVM as defined in the JVM specification. 



\end{document}
