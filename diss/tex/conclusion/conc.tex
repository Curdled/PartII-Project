\documentclass[float=false, crop=false]{standalone}
\usepackage[subpreambles=true]{standalone}
\usepackage{import}

\usepackage{subfiles}
\usepackage[backend=biber,style=numeric,sorting=none]{biblatex}
\usepackage[pdfborder={0 0 0}]{hyperref}    % turns references into hyperlinks
\usepackage[margin=25mm]{geometry}  % adjusts page layout
\usepackage{graphicx}  % allows inclusion of PDF, PNG and JPG images
\usepackage[utf8]{inputenc}
\usepackage{textcomp}
\usepackage{import}
\usepackage[font=small,labelfont=bf]{caption}

\usepackage{amsmath}

\usepackage{csquotes}
\usepackage{color}

\usepackage{verbatim}

\newlength\gwidth
\newlength\gheight
\setlength{\gwidth}{\textwidth}
\setlength{\gwidth}{\textheight}

\newcommand{\namefig}{\textbf{Figure}~}

\begin{document}

The project was a success. I implemented the whole Haskell
pipeline from start to finish, completing each work package on or
before the time outlined in the proposal timeline. I also implemented
all extensions that were proposed in the project proposal. 
All units tests written were passed by the compiler implementation (JVHC). 
A stage of the compiler was even proved correct through
a formal treatment of two simple calculus, a mapping between them
and formal transition semantics. This lead to proving that a translation
relation preserved closely the evaluation semantics. This proof was then 
used in the implementation of the code generation stage of the compiler.
The evaluation section showed comparable performance of specific programs
compiled under both JVHC and GHC (JVHC even produced a program to compute
the $n$th Fibonacci number with the same asymptotic complex as the Java
implementation). The \verb|.class| files produced can also be mixed with 
bytecode files produced from \verb|javac|. The functional inlining also
seemed to provided a benefit in performance and memory usage for certain
programs. 

There are definitely parts of the compiler which could do with improvement.
The code generation stage of the pipeline takes longer than all other stages 
combined. It would be useful to investigate why this stage takes so long 
and try to find a solution which runs faster.
Inlining is not always a good idea, this compiler would be improved 
by finding better heuristics to improve the average performance
gain from using functional inlining.
There is a trade off when implementing functional inlining (and defining
the heuristics used in functional inlinig).
Depending on how the heuristics are defined either functions will
be inlined to frequently leading to larger code size and possible
work duplication. On the other hand it could be the case that 
functional inlining allow other optimizations, therefore we want to 
inline many functions in the hope of increased performance.

\section{Summary of completed work}

This is a summary of features which were implemented in the construction
of the JVHC compiler:

\begin{itemize}

  \item Lexer implemented using Alex.

  \item A Haskell LR(0) parser implemented in Happy.

  \item A kind inference algorithm.

  \item A type inference algorithm.

  \item A algorithm to go from inputted syntax tree to valid
    System F lambda calculus.

  \item A function inlining optimization stage.

  \item A constant folding optimization stage.

  \item A code generation stage which outputted a set of \verb|.class|
    files which can be zipped into a \verb|.jar| and executed.

  \item A benchmarking framework allowing programs to be run on the JVM and 
    result to be collected.

  \item An analysis of resulting programs generated by JVHC.
\end{itemize}
Over the course of completing this project I have gained many
skills in writing larger software project and managing the complexity associated with
a large amount of code files. I have also learned how to write programs in the 
style of a Haskell programmer, the style Haskell is 
very different style of writing code when compared to Java or an OOP
programming language. I have learn about call-by-name, call-by-need and 
call-by-value evaluation and how to implement call-by-need evaluation
in a call-by-value evaluation scheme. I have learned about the Haskell
type system and implemented an algorithm which can run type inference
for Haskell 98 programs. I have learned about how to evaluate different implementation
choices. I believe targeting the JVM was a good idea since I could focus
on higher level concepts and not overly concern myself with 
implementing stack frames and a garbage collection algorithm. 
Since the JVM is very popular there existed a plethora of tools which can be 
used to debug outputted \verb|.class| files which was invaluable. 


\section{Future Work}

I believe was well as the above mentioned refinements to 
parts of the current implementation further work could be carried out 
to improve the compiler:

\begin{itemize}
  \item Strictness analysis -- Checking if an argument to an
    expression can first be reduce to a value and then pass
    to the function. Then this could allow a transformation 
    (reducing to a value before applying as an argument) to be used 
    on very small expressions, or expressions were it is known the expression 
    will be used in the body of the function.

  \item Dead code elimination -- If a function is never
    called by an other function which is self is not dead
    then don't generate code for this function. This can
    reduce the size of compiled programs, but will never
    increase the size.

  \item User-friendly Interface -- Define a wrapper class
    around the currently outputted \verb|.class| files
    which will also better interaction between Java code and the
    \verb|.class| files generated from JVHC. It would also
    be useful to allow Java functions to be exposed to the JVHC 
    compiler so easily making using the \verb|foreign| keyword 
    as mentioned the evaluation section.

  \item Implement type classes -- Extent all stages of the pipeline to 
    include type classes as defined by the Haskell 98 report 
    \cite{haskell98-spec}.
\end{itemize}

\end{document}
